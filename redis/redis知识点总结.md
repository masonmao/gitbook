# redis知识点总结

[TOC]

## 简单动态字符串

### 数据结构

```c++
struct sdshdr {
  //记录buf中已经使用字节的数量，等于sds所保存的字符串的长度
  int len; 
  //记录buf中未使用字节的数量
  int free;
  //字节数组，用于保存字符串
  char buf[];
}
```

### 为什么redis要自己实现sds而不直接使用C字符串

1.常数时间复杂度获取字符串长度

因为C字符串不记录自身的长度信息，所以获取C字符串长度需要遍历整个字符串，知道遇到空字符串为止，时间复杂度是O(N)。而sds的len属性记录了字符串的长度，时间复杂度O(1)。

2.杜绝缓冲区溢出

C字符串未记录自身长度，容易造成缓冲区内存溢出。SDS的空间分配策略完全杜绝了缓冲区溢出的可能性，API在修改时会先检查SDS空间是否满足需求，如果不满足，则会分配内存扩展至所需大小。

3.减少修改字符串时带来的内存重分配次数

因为C字符串本身不记录自身的长度，C字符串的底层实现总是一个N+1长度的数组，因此每次对这个字符串进行增长或减少操作时，都会重新分配内存。内存分配涉及复杂的算法，可能还会涉及到系统调用，所以比较耗时。

SDS通过未使用空间解决了字符串长度和底层数组长度之间的关联关系，实现了空间预分配和惰性删除的两种优化策略。

1）空间预分配

用于字符串的增长操作，即程序不仅会分配修改所必需的的空间，还会额外分配未使用空间。分配策略如下：

- 如果对SDS修改之后，SDS的长度小于1M，那么额外分配和len同样属性的未使用空间，即此时len和free的值将相同。
- 如果修改之后SDS的长度超过1M，那么程序会额外分配1M的未使用空间。

2）惰性空间释放

用于SDS的缩短操作。当SDS的长度缩短时，程序不会立即收回多余字节，而是放在free字中以备下次使用。当然SDS提供专门的API以便真正释放内存，所以不用担心会造成内存浪费的问题。

4.二进制安全

C字符串必须符合某种编码规范，并且除了末尾字符外，字符串内部不能包含空字符，否则最先被读入的空字符被认为是字符串的结尾，因此不能保存箱图片，音频、视频等二进制文件。

而SDS则是二进制安全的，所有的SDS APi都会以处理二进制的方式来处理buf数组中的数据，因此程序不会对buf的数据做任何的过滤，这样SDS可以保存任意格式的二进制数据。

5.兼容部分C字符串函数

SDS遵循了C一样的以空字符结尾的规则，总会在给Buf数组分配内存时多分配一个字符来容纳这个空字符。这样保证SDS可用使用部分字符串函数，避免了代码复用。

## 字典

字典是一种用于保存键值对的抽象出具结构，redis将字典作为数据库的底层实现，哈希键的底层实现之一也是字典。

### 字典的实现

Redis的字典使用哈希表作为底层实现，哈希表的每个节点都保存了字典中的一个键值对。

#### 哈希表

```c
//哈希表结构体
typedef struct dictht {
    dictEntry **table;      //哈希表数组，存放哈希表节点
    unsigned long size;     //哈希表大小
    unsigned long sizemask; // 哈希表大小掩码，用于计算索引值，总是等于 size - 1
    unsigned long used;     //哈希表已有节点（键值对）数量
} dictht;
```

#### 哈希表节点

```c
//哈希表节点，存放键值对和指向下一个哈希节点的指针
typedef struct dictEntry {
    void *key;  //key
  
  	//v的值可以是一个指针，一个uint64_t的整数，或者是一个int64_t的整数
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v; 
    //指向下一个哈希表节点的指针，连接哈希值相同的键值对形成链表，解决键冲突的问题
    struct dictEntry *next; 
} dictEntry; 
```

#### 字典

```c
//字典，每个字典包含两个哈希表
typedef struct dict {
    dictType *type; //类型特定函数
    void *privdata; //保存类型特定函数需要使用的参数
    dictht ht[2];   //保存的两个哈希表，ht[0]是真正使用的，ht[1]会在rehash时使用
    long rehashidx; /* rehashing not in progress if rehashidx == -1 rehash进度，如果不等于-1，说明还在进行rehash*/
    unsigned long iterators; /* number of iterators currently running 正在运行中的迭代器数量*/
} dict;
```

ht[1]和rehashidx都是和rehash相关的属性

### 哈希算法

向字典中添加键值对时，主要执行以下两个过程

1. 使用字典的哈希函数，计算key的哈希值

   ```c
   hash = dict->type->hashFunction(key);
   ```

2. 根据哈希表的sizemask属性和哈希值，计算索引值

   ```c
   index = hash & dict->ht[x]->sizemask;
   ```

### 解决键冲突

redis的哈希表使用链地址法解决键冲突。哈希节点中的next指针指向同一哈希表索引上的下一个节点，形成单链表。由于dictEntry节点的链表只有next指针，没有指向链表尾结点的指针，因此为了保证插入速度，新节点总是被添加到链表的表头位置。

![image-20190831100653438](/Users/maoxiangxin/Library/Application Support/typora-user-images/image-20190831100653438.png)

![image-20190831100722653](/Users/maoxiangxin/Library/Application Support/typora-user-images/image-20190831100722653.png)

### rehash

哈希表保存的键值对数量过多或过少时，都需要对哈希表的大小进行相应的扩展或者收缩，以保证负载因子维持在合理的范围之内。

负载因子计算公式如下：load_factor = ht[0].used / ht[0].size

#### rehash的主要步骤：

1. 为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是ht[0].used 属性的值）。

   - 如果执行的是扩展操作， 那么 `ht[1]` 的大小为第一个大于等于 `ht[0].used * 2` 的 ![2^n](https://box.kancloud.cn/2015-09-13_55f512f991fc2.png) （`2` 的 `n` 次方幂）；

   - 如果执行的是收缩操作， 那么 `ht[1]` 的大小为第一个大于等于 `ht[0].used` 的 ![2^n](https://box.kancloud.cn/2015-09-13_55f512f991fc2.png) 。

2. 将保存在 `ht[0]` 中的所有键值对 rehash 到 `ht[1]` 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 `ht[1]` 哈希表的指定位置上。

3. 当 `ht[0]` 包含的所有键值对都迁移到了 `ht[1]` 之后 （`ht[0]` 变为空表）， 释放 `ht[0]` ， 将 `ht[1]` 设置为 `ht[0]` ， 并在 `ht[1]` 新创建一个空白哈希表， 为下一次 rehash 做准备。

#### 什么情况下会进行rehash

当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作：

1. 服务器目前没有在执行 BGSAVE 命令或者BGREWRITEAOF 命令， 且哈希表的负载因子大于等于 `1`； 
2. 服务器目前正在执行 BGSAVE 命令或者BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 `5` ；

当哈希表的负载因子小于 `0.1` 时， 程序自动开始对哈希表执行收缩操作。

根据 BGSAVE 命令或 BGREWRITEAOF 命令是否正在执行， 服务器执行扩展操作所需的负载因子并不相同， 这是因为在执行 BGSAVE 命令或BGREWRITEAOF 命令的过程中， Redis 需要创建当前服务器进程的子进程， 而大多数操作系统都采用写时复制（[copy-on-write](http://en.wikipedia.org/wiki/Copy-on-write)）技术来优化子进程的使用效率， 所以在子进程存在期间， 服务器会提高执行扩展操作所需的负载因子， 从而尽可能地避免在子进程存在期间进行哈希表扩展操作， 这可以避免不必要的内存写入操作， 最大限度地节约内存。

#### 渐进式rehash

当redis数据量比较大，如哈希表中保存了几百万、几千万甚至上亿的数据时，如果一次性将这些数据进行rehash操作，如此庞大的计算量可能会导致服务器在一段时间内不可用。因此，为了保证服务器的高可用，redis采取了渐进式rehash的方法，通过多次、渐进式的将ht[0]的数据rehash到表ht[1]中。

以下是哈希表渐进式 rehash 的详细步骤：

1. 为 `ht[1]` 分配空间， 让字典同时持有 `ht[0]` 和 `ht[1]` 两个哈希表。
2. 在字典中维持一个索引计数器变量 `rehashidx` ， 并将它的值设置为 `0` ， 表示 rehash 工作正式开始。
3. 在 rehash 进行期间， 每次对字典执行**添加、删除、查找**或者**更新**操作时， 程序除了执行指定的操作以外， 还会顺带将 `ht[0]` 哈希表在 `rehashidx` 索引上的所有键值对 rehash 到 `ht[1]` ， 当 rehash 工作完成之后， 程序将 `rehashidx` 属性的值增一。
4. 随着字典操作的不断执行， 最终在某个时间点上， `ht[0]` 的所有键值对都会被 rehash 至 `ht[1]` ， 这时程序将 `rehashidx` 属性的值设为 `-1` ， 表示 rehash 操作已完成。

#### 渐进式rehash期间，数据增删改查键操作那个表？

渐进式rehash期间，字典同时存在ht[0]和ht[1]两个表，因此字典的查找、更新和删除会在两个表中进行	。比如说， 要在字典里面查找一个键的话， 程序会先在 `ht[0]` 里面进行查找， 如果没找到的话， 就会继续到 `ht[1]` 里面进行查找， 诸如此类。

另外， 在渐进式 rehash 执行期间，** 新添加到字典的键值对一律会被保存到 `ht[1]` 里面**， 而 `ht[0]` 则不再进行任何添加操作： 这一措施保证了 `ht[0]` 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。